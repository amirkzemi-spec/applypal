# bot_core/helpers_voice.py
import os, asyncio, subprocess
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from telegram import Update, InputFile
from telegram.ext import ContextTypes

# ---------------------------------------
# ğŸ§© Optional import guard for Railway
# ---------------------------------------
try:
    from pydub import AudioSegment
except Exception as e:
    print("âš ï¸ Audio library not fully available:", e)
    AudioSegment = None

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# -----------------------------------------------------------
# ğŸ™ï¸ Convert user voice â†’ text
# -----------------------------------------------------------
async def process_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Transcribe user voice messages to text and forward to text handler."""
    try:
        tg_file = await update.message.voice.get_file()
        await tg_file.download_to_drive("voice.ogg")

        if not AudioSegment:
            await update.message.reply_text("ğŸ”‡ Ù…Ø§Ú˜ÙˆÙ„ ØµÙˆØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø³Ø±ÙˆØ± ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª.")
            return

        AudioSegment.from_file("voice.ogg").export("voice.wav", format="wav")

        with open("voice.wav", "rb") as audio:
            transcript = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=audio,
            )

        text = getattr(transcript, "text", "").strip()
        if not text:
            await update.message.reply_text("âš ï¸ ØµØ¯Ø§ÛŒ Ø´Ù…Ø§ ÙˆØ§Ø¶Ø­ Ù†Ø¨ÙˆØ¯.")
            return

        print(f"ğŸ™ï¸ Ú¯ÙØªØ§Ø± Ú©Ø§Ø±Ø¨Ø±: {text}")
        context.user_data["mode"] = "voice"

        from bot_core.handlers_basic import handle_text
        await handle_text(update, context, override_text=text)

    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª:", e)
        await update.message.reply_text("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª.")

# -----------------------------------------------------------
# ğŸ§ Convert AI text â†’ voice and send as Telegram message
# -----------------------------------------------------------
async def speak_reply(update, text: str):
    """Generate TTS reply and send as Telegram voice message (Railway-safe)."""
    try:
        await update.message.chat.send_action(action="typing")
        await asyncio.sleep(1.2)

        clean_text = text.strip()
        if len(clean_text) < 30 or clean_text.count(" ") < 4:
            print("ğŸ’¬ Short text detected â€” skipping voice.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return

        # ğŸ§­ Detect if running on Railway
        is_railway = os.getenv("RAILWAY_ENVIRONMENT") is not None
        if is_railway:
            print("ğŸš€ Detected Railway environment â€” skipping voice generation.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return

        # ğŸ§  Generate TTS (MP3)
        print("ğŸ¤ Generating TTS with OpenAI...")
        mp3_path = Path("temp_voice.mp3")
        wav_path = Path("temp_voice.wav")
        ogg_path = Path("temp_voice.ogg")

        with client.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=clean_text[:1000],
        ) as response:
            response.stream_to_file(mp3_path)

        # Verify MP3
        if not mp3_path.exists() or mp3_path.stat().st_size < 2000:
            print("âš ï¸ Empty MP3 file â€” skipping voice.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return
        print(f"âœ… MP3 size: {mp3_path.stat().st_size/1000:.1f} KB")

        # Ensure pydub is available
        if not AudioSegment:
            print("âš ï¸ Audio library not available â€” skipping ffmpeg conversion.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return

        # Convert MP3 â†’ WAV â†’ OGG
        AudioSegment.from_file(mp3_path, format="mp3") \
            .set_frame_rate(16000).set_channels(1) \
            .export(wav_path, format="wav")

        subprocess.run([
            "ffmpeg", "-y",
            "-i", str(wav_path),
            "-acodec", "libopus",
            "-b:a", "96k",
            "-ar", "16000",
            "-ac", "1",
            "-application", "voip",
            str(ogg_path)
        ], check=True)

        # Verify OGG
        if not ogg_path.exists() or ogg_path.stat().st_size < 2000:
            print("âš ï¸ Empty OGG file â€” skipping voice.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return
        print(f"âœ… OGG size: {ogg_path.stat().st_size/1000:.1f} KB")

        # Send voice
        with open(ogg_path, "rb") as voice_file:
            await update.message.chat.send_voice(
                voice=InputFile(voice_file, filename="voice.ogg"),
                caption="ğŸ§ Ù¾Ø§Ø³Ø® ØµÙˆØªÛŒ Ø§Ø² Ù†ÛŒÚ©Ø§ ÙˆÛŒØ²Ø§",
                parse_mode="Markdown",
            )

        print(f"âœ… Voice sent successfully ({ogg_path.stat().st_size/1000:.1f} KB)")
        print("ğŸ“‚ Saved temp_voice.ogg for manual inspection â€” open it to verify sound.")

    except Exception as e:
        print(f"âŒ Error in speak_reply: {e}")
        await update.message.reply_text("âš ï¸ Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® ØµÙˆØªÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.")

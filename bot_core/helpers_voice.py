# bot_core/helpers_voice.py
import os, asyncio, subprocess
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from pydub import AudioSegment
from telegram import Update, InputFile
from telegram.ext import ContextTypes

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ™ï¸ Convert user voice â†’ text
async def process_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        tg_file = await update.message.voice.get_file()
        await tg_file.download_to_drive("voice.ogg")

        AudioSegment.from_file("voice.ogg").export("voice.wav", format="wav")
        with open("voice.wav", "rb") as audio:
            transcript = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=audio,
            )
        text = getattr(transcript, "text", "").strip()
        if not text:
            await update.message.reply_text("âš ï¸ ØµØ¯Ø§ÛŒ Ø´Ù…Ø§ ÙˆØ§Ø¶Ø­ Ù†Ø¨ÙˆØ¯.")
            return

        print(f"ğŸ™ï¸ Ú¯ÙØªØ§Ø± Ú©Ø§Ø±Ø¨Ø±: {text}")

        # âœ… mark mode as voice
        context.user_data["mode"] = "voice"

        from bot_core.handlers_basic import handle_text
        await handle_text(update, context, override_text=text)

    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª:", e)
        await update.message.reply_text("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª.")


# -----------------------------------------------------------
# ğŸ§ Convert AI text â†’ voice and send as Telegram message
# -----------------------------------------------------------
async def speak_reply(update, text: str):
    try:
        await update.message.chat.send_action(action="typing")
        await asyncio.sleep(1.2)

        clean_text = text.strip()
        if len(clean_text) < 30 or clean_text.count(" ") < 4:
            print("ğŸ’¬ Short text detected â€” skipping voice.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return

        tts_input = clean_text[:1000]
        remaining = clean_text[1000:]

        print("ğŸ¤ Generating TTS with OpenAI...")
        mp3_path = Path("temp_voice.mp3")
        wav_path = Path("temp_voice.wav")
        ogg_path = Path("temp_voice.ogg")   # âœ… restored

        # --- Generate MP3 via OpenAI streaming
        with client.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=tts_input,
        ) as response:
            response.stream_to_file(mp3_path)

        if not mp3_path.exists() or mp3_path.stat().st_size < 2000:
            print("âš ï¸ Empty MP3 file â€” skipping voice.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return
        print(f"âœ… MP3 size: {mp3_path.stat().st_size/1000:.1f} KB")

        # --- Convert MP3 â†’ WAV (mono, 16 kHz)
        AudioSegment.from_file(mp3_path, format="mp3") \
            .set_frame_rate(16000).set_channels(1) \
            .export(wav_path, format="wav")

        # --- Use ffmpeg to ensure proper Opus OGG container (Telegram VOIP mode, higher quality)
        subprocess.run([
            "ffmpeg", "-y",
            "-i", str(wav_path),
            "-acodec", "libopus",
            "-b:a", "96k",            # âœ… higher bitrate for clearer speech
            "-ar", "16000",           # sample rate Telegram expects
            "-ac", "1",               # mono
            "-application", "voip",   # âœ… required for Telegram voice
            str(ogg_path)
        ], check=True)


        if not ogg_path.exists() or ogg_path.stat().st_size < 2000:
            print("âš ï¸ Empty OGG file â€” skipping voice.")
            await update.message.reply_text(clean_text, parse_mode="Markdown")
            return
        print(f"âœ… OGG size: {ogg_path.stat().st_size/1000:.1f} KB")

        # --- Send to Telegram (test version keeps file)
        from telegram import InputFile

        with open(ogg_path, "rb") as voice_file:
            await update.message.chat.send_voice(
                voice=InputFile(voice_file, filename="voice.ogg"),
                caption="ğŸ§ Ù¾Ø§Ø³Ø® ØµÙˆØªÛŒ Ø§Ø² Ù†ÛŒÚ©Ø§ ÙˆÛŒØ²Ø§",
                parse_mode="Markdown",
            )

        print(f"âœ… Voice sent successfully ({ogg_path.stat().st_size/1000:.1f} KB)")

        # --- keep OGG for manual playback test
        print("ğŸ“‚ Saved temp_voice.ogg for manual inspection â€” open it to verify sound.")

        # --- Optional cleanup (disabled for debugging)
        # for f in (mp3_path, wav_path, ogg_path):
        #     if Path(f).exists():
        #         os.remove(f)

        if remaining:
            await asyncio.sleep(1)
            await update.message.reply_text(remaining, parse_mode="Markdown")

    except Exception as e:
        print(f"âŒ Error in speak_reply: {e}")
        await update.message.reply_text("âš ï¸ Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® ØµÙˆØªÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.")
